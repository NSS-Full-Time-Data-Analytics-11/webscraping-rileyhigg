{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d87b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Start by performing a GET request on the url above and convert the response into a BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs/'\n",
    "\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137176cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026cf66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2bbcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fae0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Use the .find method to find the tag containing the first job title (\"Senior Python Developer\"). Hint: can you find a tag type and/or a class that could be helpful for extracting this information? Extract the text from this title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aff6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now, use what you did for the first title, but extract the job title for all jobs on this page. Store the results in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df91e95e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobs = soup.findAll('h2')\n",
    "print(type(jobs))\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f340869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobtext = [x.text for x in jobs]\n",
    "jobtext"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba6225a3",
   "metadata": {},
   "source": [
    "##Finally, extract the companies, locations, and posting dates for each job. \n",
    "\n",
    "For example, the first job has a company of \"Payne, Roberts and Davis\", a location of \"Stewartbury, AA\", and a posting date of \"2021-04-08\". \n",
    "\n",
    "Ensure that the text that you extract is clean, meaning no extra spaces or other characters at the beginning or end.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f90eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h3').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af25e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "companies = soup.findAll('h3')\n",
    "print(type(companies))\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915fe062",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "companytext = [x.text for x in companies]\n",
    "companytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p', attrs={'class' : 'location'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = soup.findAll('p', attrs={'class' : 'location'})\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c717769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locationtext = [x.text for x in location]\n",
    "locationtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11005e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locationtext = [x.strip() for x in locationtext]\n",
    "locationtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('time').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b3013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date = soup.findAll('time')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ce02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datetext = [x.text for x in date]\n",
    "datetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d140797",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lists = jobtext, companytext, locationtext, datetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9531ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(jobtext, companytext, locationtext, datetext)), \n",
    "                   columns = ['Job Title', 'Company', 'Location', 'Date Posted'])\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4538fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Next, add a column that contains the url for the \"Apply\" button. Try this in two ways.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a. First, use the BeautifulSoup find_all method to extract the urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff4ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply = soup.findAll('a', string = 'Apply')\n",
    "apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1601d10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "applylink = [x.get('href') for x in apply]\n",
    "applylink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(applylink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bccead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Apply URL'] = applylink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf82ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38941d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html'\n",
    "\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba731f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', attrs = {'class' : 'content'}).find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee84a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = df['Apply URL']\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BS(response.text)\n",
    "    \n",
    "    descrip = soup.find('div', attrs = {'class' : 'content'}).find('p')\n",
    "    print(descrip.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linknav(url):\n",
    "        response = requests.get(url)\n",
    "        soup = BS(response.text)\n",
    "    \n",
    "        descrip = soup.find('div', attrs = {'class' : 'content'}).find('p')\n",
    "        print(descrip.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4ac0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Apply URL'].apply(linknav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4beef29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
